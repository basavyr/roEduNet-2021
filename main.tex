\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}


\begin{document}

\title{Implementation of an email-based alert system for large-scale system resources}

\author{\IEEEauthorblockN{Robert Poenaru$^{1,2}$}
\IEEEauthorblockA{
%$^{1}$Department of Computational Physics and Information Technology\\ 
$^{1}$\textit{Horia Hulubei} National Institute of Nuclear Physics and Engineering, Magurele, Romania\\
$^2$Doctoral School of Physics, University of Bucharest, Romania\\
robert.poenaru@nipne.ro}
}

\maketitle

\begin{abstract}
Tackling the current problems of interest for physicists that deal with various topics require lots of computing simulations. Identifying and preventing any unusual behavior within the system resources that execute large-scale calculations is a crucial process when dealing with system administration, since it can improve the run-time performance of the resources themselves and also help the physicists by obtaining the required results faster. In the present work, a simple \emph{pythonic} implementation which 1) monitors a given computing architecture (i.e., its system resources such as CPU and Memory usage), and 2) alerts a custom team of administrators via e-mail in almost real-time when certain thresholds are passed, is presented. Using existing packages written in Python, with the current implementation it is possible to send e-mails to a predefined list of clients containing detailed information about any machine running outside the "normal" parameters.
\end{abstract}

\begin{IEEEkeywords}
python, system resources, alerting, email, smtp, monitoring, watchdog
\end{IEEEkeywords}

\section{Introduction}
\label{section-introduction}
The computing resources within a physics department must be up to speed and ready for a continuous run-time of small-, medium-, but also large-scale simulations, in order to assure a consistent and optimal workflow for the research teams that require calculations. Usually, there is a cohesive workflow between the scientists that want to run their simulations and the system administration (sysadmins) team that provides the necessary resources for executing them. The sysadmins must check that the resources which are performing calculations behave well, but they must also take care of the computing equipment that is sitting in \emph{idle}-mode, in case new requests for allocating resources are issued by scientists. The process of resource management is crucial since it involves many factors in deciding which are the most optimal compute nodes that could start a new job, in terms of efficiency and speedup \cite{paya2015resource}, these being deciding factors in the total run-time of the simulations themselves.
\par Proper job allocation, management, and execution will result in minimal impact of resource slowdown, process blocking, or even dead-locks in the executing pipeline, giving the possibility of the researchers to obtain the desired numerical results in as fast as possible. 
\par On the other hand, any code optimization \cite{codeoptimization2,codeoptimization1} on the submitted simulations (done exclusively by the scientific teams) will also take advantage of the allocated resources, since \emph{better code} implies faster execution, lower impact on the memory pool and much lower probability of program interruption.
\par One can conclude that indeed, better resource management (done by the sysadmins) will result in better code execution, helping thus the scientists, but in the same way, any code optimization made by scientists will help the sysadmins, since the degree of failure within the executing simulations stack could be decreased. This reciprocal-mode of improvements (for both \emph{communities}) is sketched in Fig. \ref{community-optimization}, where the key characteristics of both \emph{communities} (i.e., physicists issuing simulations and sysadmins dealing with computing management) are emphasized. The arrows signify the \emph{reciprocal improvement cycle} between the two.
\par However, due to the large degree of complexity of the underlying computing infrastructure, issues related to memory bandwidth, network stability, CPU throttling \cite{ibm}, cache availability \cite{awscache} and so on are highly probable, especially when the machines are running continuously. Frequent updates, unexpected network traffic, errors within the services running in the application layer \cite{pstree} could also affect the idling nodes. While the former issues will only affect the simulations that are currently being executed, the latter set of issues could produce unexpected delays in the starting process of the job queue \cite{jobqeue}, which will increase the wait-time of simulation results. One can see that indeed, any issues which occur with the computing resources, even the idling ones, can affect the workflow of the research teams, causing the entire research department to finish their projects. As such, the sysadmins are essential by taking the proper actions on the computing infrastructure.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.75]{figs/scientific_sysadmin_optimization.pdf}}
\caption{A basic relationship between the scientific community that issues simulations to be executed on the computing resources, and the system administration team that deals with process allocation, execution and management of resources.}
\label{community-optimization}
\end{figure}

\par Unfortunately, there will always be moments when the sysadmin team that is monitoring a particular computing node (e.g., cluster, server racks, etc.) cannot keep track of the \emph{health status} of the entire architecture at all times (although recently, some interesting models emerged within the literature that could improve the machine health status \cite{hasani2019machine,lin2020health} in an automated way). In order to properly, securely and efficiently maintain a large-scale server infrastructure up and running (as the one that is present in a physics research department), there must be some kind of \emph{alert system} that is constantly analyzing the system resources, and tries to identify unusual behavior. When a potential malfunction is identified, the core-feature of the alert system is to inform the sysadmins with regards to the occurring issue(s).
\par In the present work, such a model is implemented; namely, a service that analyzes the logs generated by the system resources of a computing cluster (i.e., CPU usage, RAM usage and so on) and compares the values with predefined thresholds decides if the monitored values indicate some unusual behavior. If indeed, the thresholds are exceeded, the service will immediately raise an alert, sending information with the occurring issue to the sysadmin teams, which then can take action.
\par The paper is organized as follows: in Section \ref{section-introduction}, a brief introduction of system administration is made, with motivation for implementing an alert system within a large-scale computing infrastructure. Furthermore, in Section \ref{section-alert-workflow} the general overview on how the \emph{pythonic} implementation of the current research actually works, mentioning its main features and advantages. Section \ref{section-data-ingest} discusses the services that are used in order to keep track of changes within the log-files generated by the system resources, while Section \ref{section-thresholds} presents the method of deciding between \emph{normal} and \emph{unusual} behavior of said resources. Finally, an overview of the implementation which sends the actual alerts to the sysadmin team (via email) is made in Section \ref{section-email-alert}, followed up by some concluding remarks and potential improvements of the project itself, given in Section \ref{section-conclusions}.

\section{Alert-System Workflow}
\label{section-alert-workflow}

Implementation of the alert system is quite straightforward, following a procedure that does not require too much information. Fig. \ref{alert-system-general-workflow} shows how the process of taking action (i.e., fixing occurring issues on the computing nodes) by the administration team is taking place. Usually, the personnel that deals with system administration is located on-site, since the need-of-action would sometimes require physical access on the barebone servers. However, considering the current pandemic situation \cite{ciotti2020covid}, the paradigm has shifted a lot to remote work, with possibility of remote access by the sysadmins \cite{sallow2020client} to any computing cluster located in the departments they monitor. 

\begin{figure*}[htbp]
    \centering
    \includegraphics[scale=1.1]{figs/alert_system_improvements.pdf}
    \caption{The general workflow of a system administration team, when an alert system would be deployed on the computing resources that need to be monitored.}
    \label{alert-system-general-workflow}
\end{figure*}

\section{Watchdog - Data ingest}
\label{section-data-ingest}

\section{Thresholds - normal vs. unusual behavior}
\label{section-thresholds}

\section{Alert via email}
\label{section-email-alert}

\section{Conclusions \& Future Work}
\label{section-conclusions}

% \subsection{Figures and Tables}
% \paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
% bottom of columns. Avoid placing them in the middle of columns. Large 
% figures and tables may span across both columns. Figure captions should be 
% below the figures; table heads should appear above the tables. Insert 
% figures and tables after they are cited in the text. Use the abbreviation 
% ``Fig.~\ref{fig}'', even at the beginning of a sentence.
% \begin{table}[htbp]
% \caption{Table Type Styles}
% \begin{center}
% \begin{tabular}{|c|c|c|c|}
% \hline
% \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
% \cline{2-4} 
% \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
% \hline
% copy& More table copy$^{\mathrm{a}}$& &  \\
% \hline
% \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}

\section*{Acknowledgment}

This work done within the Department of Computational Physics and Information Technology at \emph{Horia Hulubei} National Institute of Physics and Nuclear Engineering. The development was funded by European Regional Development Fund through project CECBID-EOSC (POC/397/1/1-124405).

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
